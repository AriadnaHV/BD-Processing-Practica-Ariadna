# BD-Processing-Practica-Ariadna
Deliverable for the Big Data Processing module of the KeepCoding Bootcamp on Big Data, Artificial Intelligence, and Machine Learning (Ed. XVI).

In this practical assignment, I solved 5 exercises which involved a variety of skills in big data processing, functional programming in Scala, and practical knowledge of data manipulation and analysis using Apache Spark. 

More specifically, the skill set included:
- Apache Spark: I utilized Sparkâ€™s DataFrame and RDD APIs for large-scale data processing, showcasing my understanding of Spark's architecture and data handling capabilities.
- DataFrame operations: I performed operations such as filtering, selecting, joining, and aggregating data within DataFrames, demonstrating familiarity with Spark SQL functions and DataFrame manipulations.
- User-Defined Functions (UDF): I created a UDF to categorize numbers as "Par" (even) or "Impar" (odd), illustrating my ability to extend Spark functionality and apply custom logic to DataFrame columns.
- RDD manipulation: I created and operated on RDDs (Resilient Distributed Datasets), including transformations and actions like map and reduceByKey, showcasing competency in working with unstructured data.
- Data Transformation and Aggregation: I demonstrated the ability to transform and aggregate data, such as calculating averages and totals, important for data analysis tasks.
- File Processing and ETL: I showed capability in loading and processing CSV files using Spark, which is essential for real-world data ingestion and ETL tasks (Extract, Transform, Load).
- Scala Programming: I wrote idiomatic Scala code, including pattern matching and functional programming techniques such as map, groupBy, and agg, reflecting a solid understanding of the language.
- Data Schema Management: the methods used involve understanding and managing data schemas, especially when working with structured data in DataFrames.

In Exercise 4, I suggested two different solutions: one using RDDs and Spark as required, and one using a simpler method with lists and arrays, which would be more efficient for small datasets like the one provided. 

